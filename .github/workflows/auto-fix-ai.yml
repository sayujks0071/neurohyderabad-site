name: Auto-Fix AI PR Bot

on:
  workflow_run:
    workflows:
      - "Lighthouse CI"
      - "Broken Link Checker"
      - "JSON-LD Schema Validator"
      - "Meta Tag Checker"
      - "Accessibility Audit (a11y)"
      - "Image Optimization"
      - "Spell Check"
    types:
      - completed
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  actions: read
  issues: read

jobs:
  autofix:
    # Run on workflow failures OR manual dispatch OR when workflows complete (to check for issues)
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.workflow_run && (
        github.event.workflow_run.conclusion == 'failure' ||
        github.event.workflow_run.conclusion == 'success'
      ))
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: false

      - name: Download workflow artifacts
        if: github.event.workflow_run != null
        uses: dawidd6/action-download-artifact@v3
        continue-on-error: true
        with:
          workflow: ${{ github.event.workflow_run.workflow_id }}
          run_id: ${{ github.event.workflow_run.id }}
          path: artifacts

      - name: Create empty artifacts directory (if manual trigger)
        if: github.event.workflow_run == null
        run: mkdir -p artifacts && echo "Manual trigger - no artifacts to download" > artifacts/manual-trigger.txt

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Aggregate all reports
        id: aggregate
        timeout-minutes: 5
        continue-on-error: true
        run: |
          cat > aggregate-reports.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          const issues = {
            lighthouse: [],
            brokenLinks: [],
            schema: [],
            metaTags: [],
            accessibility: [],
            images: [],
            spelling: []
          };
          
          function findFiles(dir, files = []) {
            if (!fs.existsSync(dir)) return files;
            
            const items = fs.readdirSync(dir);
            for (const item of items) {
              const fullPath = path.join(dir, item);
              const stat = fs.statSync(fullPath);
              
              if (stat.isDirectory()) {
                findFiles(fullPath, files);
              } else {
                files.push(fullPath);
              }
            }
            return files;
          }
          
          const artifactFiles = findFiles('artifacts');
          
          console.log('Found', artifactFiles.length, 'artifact files');
          
          if (artifactFiles.length === 0) {
            console.log('No artifacts found - creating empty report');
            const emptyReport = {
              summary: {
                lighthouse: 0,
                brokenLinks: 0,
                schema: 0,
                metaTags: 0,
                accessibility: 0,
                images: 0,
                spelling: 0
              },
              details: {
                lighthouse: [],
                brokenLinks: [],
                schema: [],
                metaTags: [],
                accessibility: [],
                images: [],
                spelling: []
              }
            };
            fs.writeFileSync('aggregated-report.json', JSON.stringify(emptyReport, null, 2));
            fs.writeFileSync('fixes.patch', '# No fixes needed - no artifacts found');
            process.exit(0);
          }
          
          artifactFiles.forEach(file => {
            try {
              const content = fs.readFileSync(file, 'utf8');
              
              // Try to parse as JSON
              try {
                const json = JSON.parse(content);
                
                // Lighthouse reports
                if (json.categories) {
                  Object.entries(json.categories).forEach(([key, value]) => {
                    if (value.score < 0.9) {
                      issues.lighthouse.push({
                        category: value.title,
                        score: Math.round(value.score * 100),
                        file: file
                      });
                    }
                  });
                }
                
                // Accessibility reports
                if (json.totalIssues) {
                  issues.accessibility.push({
                    total: json.totalIssues,
                    critical: json.criticalIssues,
                    categories: json.categories
                  });
                }
                
              } catch (e) {
                // Not JSON, check for text patterns
                if (content.includes('BROKEN') || content.includes('404')) {
                  const lines = content.split('\n').filter(l => l.includes('http'));
                  issues.brokenLinks.push(...lines);
                }
              }
            } catch (error) {
              console.log('Could not read', file);
            }
          });
          
          const report = {
            summary: {
              lighthouse: issues.lighthouse.length,
              brokenLinks: issues.brokenLinks.length,
              schema: issues.schema.length,
              metaTags: issues.metaTags.length,
              accessibility: issues.accessibility.length,
              images: issues.images.length,
              spelling: issues.spelling.length
            },
            details: issues
          };
          
          fs.writeFileSync('aggregated-report.json', JSON.stringify(report, null, 2));
          
          console.log('\nAggregated Report:');
          console.log(JSON.stringify(report.summary, null, 2));
          
          // Check if there are actionable issues
          const totalIssues = Object.values(report.summary).reduce((a, b) => a + b, 0);
          
          if (totalIssues === 0) {
            console.log('No issues found to fix');
            // Create empty file to indicate no fixes needed
            fs.writeFileSync('fixes.patch', '# No fixes needed - all checks passed');
            process.exit(0);
          }
          EOF
          
          node aggregate-reports.js

      - name: Generate AI fixes
        id: ai_fix
        if: always()
        timeout-minutes: 5
        continue-on-error: true
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          # Create artifacts directory for debugging
          mkdir -p autofix-debug
          
          # Check if report file exists
          if [ ! -f aggregated-report.json ]; then
            echo "No aggregated report found - creating empty patch"
            echo "# No fixes needed - no report available" > fixes.patch
            echo "# No fixes needed - no report available" > autofix-debug/prompt.txt
            echo "# No fixes needed - no report available" > autofix-debug/ai-response.txt
            exit 0
          fi
          
          cat > generate-fixes.js << 'EOF'
          const fs = require('fs');
          const https = require('https');
          
          let report;
          try {
            report = JSON.parse(fs.readFileSync('aggregated-report.json', 'utf8'));
          } catch (error) {
            console.error('Failed to read aggregated report:', error.message);
            fs.writeFileSync('fixes.patch', '# No fixes needed - could not read report');
            fs.writeFileSync('autofix-debug/error.txt', `Failed to read aggregated report: ${error.message}`);
            process.exit(0);
          }
          
          // Create a concise prompt with properly escaped JSON
          const detailsJson = JSON.stringify(report.details, null, 2).replace(/`/g, '\\`').replace(/\$/g, '\\$');
          
          // Save prompt snapshot for debugging
          const prompt = 'You are a Next.js web development expert. Review these audit results and generate ONLY the code changes needed to fix them.\n\n' +
            'Audit Results:\n' +
            '- Lighthouse issues: ' + report.summary.lighthouse + '\n' +
            '- Broken links: ' + report.summary.brokenLinks + '\n' +
            '- Schema issues: ' + report.summary.schema + '\n' +
            '- Meta tag issues: ' + report.summary.metaTags + '\n' +
            '- Accessibility issues: ' + report.summary.accessibility + '\n' +
            '- Image issues: ' + report.summary.images + '\n\n' +
            'Detailed Issues:\n' +
            '```json\n' +
            detailsJson + '\n' +
            '```\n\n' +
            'Generate a git patch file that fixes these issues. Focus on:\n' +
            '1. Adding missing alt tags to images\n' +
            '2. Fixing meta descriptions that are too short/long\n' +
            '3. Correcting JSON-LD schema errors\n' +
            '4. Fixing broken internal links\n' +
            '5. Improving accessibility (ARIA labels, contrast)\n\n' +
            'Return ONLY valid git diff format. Be surgical - only change what\'s necessary.';
          
          // Save prompt to debug artifact
          fs.writeFileSync('autofix-debug/prompt.txt', prompt);
          console.log('Prompt saved to autofix-debug/prompt.txt');
          
          const apiKey = process.env.OPENAI_API_KEY;
          
          if (!apiKey || apiKey === '') {
            console.log('No OpenAI API key provided, using fallback fixes');
            
            // Fallback: Generate simple rule-based fixes
            let patches = [];
            
            // Fix common issues
            if (report.details.accessibility.length > 0) {
              patches.push('# Add alt text to images without it');
            }
            
            if (patches.length > 0) {
              fs.writeFileSync('fixes.patch', patches.join('\n'));
              console.log('Generated fallback fixes');
              process.exit(0);
            } else {
              console.log('No fixable issues detected');
              fs.writeFileSync('fixes.patch', '# No fixes needed - no actionable issues found');
              process.exit(0);
            }
          } else {
            // Call OpenAI API using Promise to ensure we wait for completion
            new Promise((resolve, reject) => {
              const data = JSON.stringify({
                model: 'gpt-4o-mini',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert web developer who generates precise git patches to fix web issues. Return only valid git diff format.'
                  },
                  {
                    role: 'user',
                    content: prompt
                  }
                ],
                temperature: 0.3,
                max_tokens: 4000
              });
              
              const options = {
                hostname: 'api.openai.com',
                port: 443,
                path: '/v1/chat/completions',
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'Authorization': `Bearer ${apiKey}`,
                  'Content-Length': data.length
                }
              };
              
              const req = https.request(options, (res) => {
                let body = '';
                
                res.on('data', (chunk) => {
                  body += chunk;
                });
                
            res.on('end', () => {
              try {
                // Save full AI response to debug artifact
                fs.writeFileSync('autofix-debug/ai-response.txt', body);
                console.log('AI response saved to autofix-debug/ai-response.txt');
                
                if (res.statusCode !== 200) {
                  console.error(`API request failed with status ${res.statusCode}:`, body);
                  fs.writeFileSync('fixes.patch', '# No fixes generated - API request failed');
                  fs.writeFileSync('autofix-debug/error.txt', `API request failed with status ${res.statusCode}:\n${body}`);
                  resolve();
                  return;
                }
                
                const response = JSON.parse(body);
                
                if (response.error) {
                  console.error('OpenAI API Error:', response.error.message);
                  console.error('Error type:', response.error.type);
                  fs.writeFileSync('fixes.patch', '# No fixes generated - OpenAI API error');
                  fs.writeFileSync('autofix-debug/error.txt', `OpenAI API Error: ${response.error.message}\nType: ${response.error.type}`);
                  resolve();
                  return;
                }
                
                if (!response.choices || !response.choices[0] || !response.choices[0].message) {
                  console.error('Invalid API response structure:', JSON.stringify(response, null, 2));
                  fs.writeFileSync('fixes.patch', '# No fixes generated - invalid API response');
                  fs.writeFileSync('autofix-debug/error.txt', `Invalid API response structure:\n${JSON.stringify(response, null, 2)}`);
                  resolve();
                  return;
                }
                
                const content = response.choices[0].message.content;
                
                if (!content || content.trim().length === 0) {
                  console.error('Empty response from OpenAI API');
                  fs.writeFileSync('fixes.patch', '# No fixes generated - empty API response');
                  fs.writeFileSync('autofix-debug/error.txt', 'Empty response from OpenAI API');
                  resolve();
                  return;
                }
                
                // Extract patch from markdown code blocks if present
                let patch = content;
                const codeBlockMatch = content.match(/```(?:diff|patch)?\n([\s\S]*?)```/);
                if (codeBlockMatch) {
                  patch = codeBlockMatch[1];
                }
                
                fs.writeFileSync('fixes.patch', patch);
                fs.writeFileSync('autofix-debug/patch.diff', patch);
                console.log('AI-generated patch saved');
                console.log('Patch preview:');
                console.log(patch.substring(0, 500));
                resolve();
                    
              } catch (error) {
                console.error('Error parsing OpenAI response:', error.message);
                console.error('Response body:', body.substring(0, 500));
                fs.writeFileSync('fixes.patch', '# No fixes generated - parsing error');
                fs.writeFileSync('autofix-debug/error.txt', `Parsing error: ${error.message}\n\nResponse body (first 500 chars):\n${body.substring(0, 500)}`);
                resolve();
              }
                });
              });
              
              req.on('error', (error) => {
                console.error('Request error:', error.message);
                console.error('Error code:', error.code);
                fs.writeFileSync('fixes.patch', '# No fixes generated - network error');
                resolve();
              });
              
              req.setTimeout(60000, () => {
                console.error('Request timeout after 60 seconds');
                req.destroy();
                fs.writeFileSync('fixes.patch', '# No fixes generated - request timeout');
                resolve();
              });
              
              req.write(data);
              req.end();
            }).then(() => {
              process.exit(0);
            }).catch((error) => {
              console.error('Unexpected error:', error);
              fs.writeFileSync('fixes.patch', '# No fixes generated - unexpected error');
              process.exit(0);
            });
          }
          EOF
          
          node generate-fixes.js

      - name: Upload Auto-Fix debug artifacts
        if: always()
        timeout-minutes: 2
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: autofix-debug
          path: autofix-debug/
          retention-days: 30
          if-no-files-found: ignore

      - name: Validate patch
        id: validate
        if: always()
        timeout-minutes: 2
        continue-on-error: true
        run: |
          if [ ! -f fixes.patch ]; then
            echo "No patch file generated"
            echo "has_fixes=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Check if patch is just a comment (no fixes needed)
          if grep -q "^# No fixes needed" fixes.patch; then
            echo "No fixes needed - all checks passed"
            echo "has_fixes=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if [ ! -s fixes.patch ] || [ "$(wc -c < fixes.patch)" -lt 50 ]; then
            echo "Patch file is empty or too small"
            echo "has_fixes=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Patch file exists and is non-empty"
          echo "has_fixes=true" >> $GITHUB_OUTPUT
          
          # Try to apply patch in dry-run mode
          if git apply --check fixes.patch 2>&1; then
            echo "Patch can be applied cleanly"
            echo "patch_valid=true" >> $GITHUB_OUTPUT
          else
            echo "Patch has conflicts, will create as suggestion"
            echo "patch_valid=false" >> $GITHUB_OUTPUT
          fi

      - name: Apply fixes
        if: steps.validate.outputs.has_fixes == 'true' && steps.validate.outputs.patch_valid == 'true'
        timeout-minutes: 2
        continue-on-error: true
        run: |
          git config user.name "Auto-Fix Bot"
          git config user.email "autofix@neurohyderabad.org"
          
          # Apply the patch
          git apply fixes.patch
          
          # Add changed files
          git add -A

      - name: Create Pull Request
        if: steps.validate.outputs.has_fixes == 'true'
        timeout-minutes: 3
        continue-on-error: true
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: 'chore: auto-fix SEO, performance, and accessibility issues'
          title: 'ğŸ¤– Auto-Fix: Automated Code Improvements'
          body: |
            ## ğŸ¤– Auto-Fix AI PR Bot
            
            This PR was automatically generated to fix issues detected by CI workflows.
            
            ### Issues Addressed:
            
            ğŸ”¦ **Lighthouse Performance**: Optimizations for Core Web Vitals  
            ğŸ”— **Broken Links**: Fixed or updated non-working URLs  
            ğŸ“‹ **Schema/JSON-LD**: Corrected structured data markup  
            ğŸ·ï¸ **Meta Tags**: Improved SEO metadata  
            â™¿ **Accessibility**: Enhanced WCAG compliance  
            ğŸ–¼ï¸ **Images**: Added missing alt tags and optimized sizing  
            
            ### What Changed:
            
            The AI analyzed audit reports from:
            - Lighthouse CI
            - Broken Link Checker
            - Schema Validator
            - Meta Tag Checker
            - Accessibility Audit
            - Image Optimization
            
            And generated surgical code fixes for the detected issues.
            
            ### Review Checklist:
            
            - [ ] Changes look correct
            - [ ] No unintended modifications
            - [ ] Tests pass
            - [ ] Lighthouse scores improved
            
            ---
            
            **Triggered by**: ${{ github.event.workflow_run.name }}  
            **Run ID**: ${{ github.event.workflow_run.id }}  
            
            ğŸ”— [View workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          branch: autofix/ai-${{ github.run_id }}
          delete-branch: true
          labels: autofix,ai,automated
          assignees: sayujks0071
